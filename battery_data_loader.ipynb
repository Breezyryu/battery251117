{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd  # For large datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc # Garbage collection\n",
    "\n",
    "# Helper function for error messages (as per BatteryDataTool.py style)\n",
    "def err_msg(msg):\n",
    "    print(f"Error: {msg}")\n",
    "\n",
    "# Step 1: Check input path and distinguish cycler type\n",
    "def check_cycler(path):\n",
    "    if not os.path.isdir(path):\n",
    "        err_msg(f"Path does not exist or is not a directory: {path}")\n",
    "        # In a real UI, you'd use filedialog.askdirectory here.\n",
    "        return None # Indicate error or invalid path\n",
    "    return os.path.isdir(os.path.join(path, \"Pattern\"))  # PNE: True, Toyo: False\n",
    "\n",
    "# Placeholder for toyo_min_cap (from BatteryDataTool.py)\n",
    "def toyo_min_cap(path, min_cap, ini_rate):\n",
    "    # This is a simplified placeholder. Actual logic from BatteryDataTool.py would be more complex.\n",
    "    # It might involve reading file names or initial cycle data to determine min_cap.\n",
    "    if min_cap == 0:\n",
    "        # Attempt to extract from path or a specific file if not provided\n",
    "        match = re.search(r'(\d+)mAh', path)\n",
    "        if match:\n",
    "            min_cap = float(match.group(1))\n",
    "        else:\n",
    "            print(\"Warning: min_cap not provided and could not be extracted from path. Using a default of 1000.\")\n",
    "            min_cap = 1000 # Default or raise error\n",
    "    return min_cap\n",
    "\n",
    "# Placeholder for toyo_cycle_data (from BatteryDataTool.py)\n",
    "def toyo_cycle_data(raw_df, min_cap, ini_rate, chk_ir):\n",
    "    # Simplified placeholder for processing Toyo cycle data\n",
    "    # This would involve calculations like Dchg, Eff, Temp, DCIR etc.\n",
    "    df = raw_df.copy()\n",
    "    if 'Cap[mAh]' in df.columns:\n",
    "        df['Dchg'] = df['Cap[mAh]'] # Example: just copy for now\n",
    "    else:\n",
    "        df['Dchg'] = np.nan # Or handle missing column appropriately\n",
    "    df['Eff'] = 100 # Placeholder\n",
    "    df['Temp'] = 25 # Placeholder\n",
    "    df['TotlCycle'] = df['TotlCycle'].astype(int) # Ensure correct type\n",
    "    return df\n",
    "\n",
    "# Placeholder for toyo_step_Profile_data (from BatteryDataTool.py)\n",
    "def toyo_step_Profile_data(chunk_df, min_cap, cutoff, smooth):\n",
    "    # Simplified placeholder for processing Toyo profile data for a step\n",
    "    # This would involve calculating SOC, dQdV, etc.\n",
    "    df = chunk_df.copy()\n",
    "    if 'PassTime[Sec]' in df.columns:\n",
    "        df['TimeMin'] = df['PassTime[Sec]'] / 60\n",
    "    else:\n",
    "        df['TimeMin'] = np.nan\n",
    "    if 'Voltage[V]' in df.columns:\n",
    "        df['Vol'] = df['Voltage[V]']\n",
    "    else:\n",
    "        df['Vol'] = np.nan\n",
    "    df['SOC'] = 0.5 # Placeholder\n",
    "    df['dQdV'] = 0 # Placeholder\n",
    "    return df\n",
    "\n",
    "# Placeholder for pne_search_cycle (from BatteryDataTool.py)\n",
    "def pne_search_cycle(restore_path, start_cycle, end_cycle):\n",
    "    # Simplified placeholder. Actual logic would search for files containing cycle data.\n",
    "    # For now, assume all files are relevant and return a range.\n",
    "    files = [f for f in os.listdir(restore_path) if \"SaveEndData\" in f and f.endswith(\".csv\")]\n",
    "    if not files:\n",
    "        return (0, -1) # No files found\n",
    "    return (0, len(files) - 1) # Return all files for simplicity\n",
    "\n",
    "# Placeholder for pne_data (from BatteryDataTool.py)\n",
    "def pne_data(raw_df, ini_cycle):\n",
    "    # Simplified placeholder for processing PNE profile data\n",
    "    # This would involve extracting relevant columns and potentially merging.\n",
    "    df = raw_df.copy()\n",
    "    # Assuming column 27 is 'TotlCycle' and other columns are relevant data\n",
    "    df.columns = [f'col_{i}' for i in range(len(df.columns))] \n",
    "    if 'col_27' in df.columns:\n",
    "        df['TotlCycle'] = df['col_27'].astype(int)\n",
    "    else:\n",
    "        df['TotlCycle'] = ini_cycle # Default if not found\n",
    "    df['TimeMin'] = df['col_1'] / 60 if 'col_1' in df.columns else np.nan # Example mapping\n",
    "    df['Vol'] = df['col_2'] if 'col_2' in df.columns else np.nan # Example mapping\n",
    "    return df\n",
    "\n",
    "# Step 2: Toyo data loading\n",
    "def load_toyo_cycle(path, min_cap=0, ini_rate=0.2, chk_ir=True):\n",
    "    cycle_file = os.path.join(path, \"capacity.log\")\n",
    "    if not os.path.exists(cycle_file):\n",
    "        err_msg(f"Toyo cycle file not found: {cycle_file}")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f"Loading Toyo cycle data from {cycle_file}")\n",
    "    # Use Dask for large files, specifying relevant columns\n",
    "    # Assuming 'TotlCycle', 'Condition', 'Cap[mAh]' are key columns\n",
    "    try:\n",
    "        raw = dd.read_csv(cycle_file, blocksize=\"64MB\", encoding='utf-8',\n",
    "                          usecols=[\"TotlCycle\", \"Condition\", \"Cap[mAh]\"])\n",
    "    except Exception as e:\n",
    "        err_msg(f"Error reading Toyo cycle file {cycle_file}: {e}")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    min_cap = toyo_min_cap(path, min_cap, ini_rate)  # Calculate min_cap\n",
    "    processed = toyo_cycle_data(raw, min_cap, ini_rate, chk_ir)  # Apply processing logic\n",
    "    \n",
    "    # Optimize data types before computing to Pandas\n",
    "    processed = processed.astype({\n",
    "        'TotlCycle': 'int32',\n",
    "        'Condition': 'int8',\n",
    "        'Cap[mAh]': 'float32'\n",
    "    })\n",
    "    \n",
    "    return processed.compute() # Convert Dask DataFrame to Pandas DataFrame\n",
    "\n",
    "def load_toyo_profile(path, ini_cycle, end_cycle, min_cap, cutoff, ini_rate, smooth=0):\n",
    "    dfs = []\n",
    "    print(f"Loading Toyo profile data for cycles {ini_cycle} to {end_cycle}")\n",
    "    for cyc in range(ini_cycle, end_cycle + 1):\n",
    "        file = os.path.join(path, f"%06d" % cyc)\n",
    "        if not os.path.exists(file):\n",
    "            print(f"Warning: Toyo profile file not found for cycle {cyc}: {file}. Skipping.")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Use chunking for large profile files\n",
    "            chunk_reader = pd.read_csv(file, chunksize=100000, skiprows=3, encoding='utf-8',\n",
    "                                       usecols=["PassTime[Sec]", "Voltage[V]", "Current[mA]", "Step", "TotlCycle"])\n",
    "            for chunk in chunk_reader:\n",
    "                # Add TotlCycle to each chunk for merging later\n",
    "                chunk['TotlCycle'] = cyc\n",
    "                # Optimize data types within chunk\n",
    "                chunk = chunk.astype({\n",
    "                    'PassTime[Sec]': 'float32',\n",
    "                    'Voltage[V]': 'float32',\n",
    "                    'Current[mA]': 'float32',\n",
    "                    'Step': 'int16',\n",
    "                    'TotlCycle': 'int32'\n",
    "                })\n",
    "                processed = toyo_step_Profile_data(chunk, min_cap, cutoff, smooth)  # Process each chunk\n",
    "                dfs.append(processed)\n",
    "        except Exception as e:\n",
    "            err_msg(f"Error reading Toyo profile file {file}: {e}")\n",
    "            continue\n",
    "\n",
    "    if not dfs:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    # Concatenate all processed chunks. Use Dask for this if 'dfs' is very large.\n",
    "    # For now, assuming pd.concat is sufficient, but dd.concat could be used if memory becomes an issue.\n",
    "    merged = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Apply filtering if needed (e.g., based on current cutoff)\n",
    "    # if min_cap > 0 and 'Current[mA]' in merged.columns:\n",
    "    #     merged = merged[abs(merged['Current[mA]']) >= cutoff * min_cap]\n",
    "\n",
    "    gc.collect() # Explicitly release memory\n",
    "    return merged\n",
    "\n",
    "# Step 3: PNE data loading\n",
    "def load_pne_cycle(path, start_cycle, end_cycle):\n",
    "    restore_path = os.path.join(path, \"Restore\")\n",
    "    if not os.path.isdir(restore_path):\n",
    "        err_msg(f"PNE Restore directory not found: {restore_path}")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f"Loading PNE cycle data from {restore_path}")\n",
    "    # Find relevant SaveEndData files\n",
    "    files_in_restore = [os.path.join(restore_path, f) for f in os.listdir(restore_path) if \"SaveEndData\" in f and f.endswith(\".csv\")]\n",
    "    \n",
    "    if not files_in_restore:\n",
    "        err_msg(f"No PNE SaveEndData files found in {restore_path}")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Use pne_search_cycle to get the range of files to read\n",
    "    # This placeholder assumes all files are relevant for now.\n",
    "    # In a real scenario, pne_search_cycle would filter based on start_cycle/end_cycle.\n",
    "    file_indices = pne_search_cycle(restore_path, start_cycle, end_cycle)\n",
    "    if file_indices[1] < file_indices[0]:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    selected_files = [files_in_restore[i] for i in range(file_indices[0], file_indices[1] + 1)]\n",
    "\n",
    "    try:\n",
    "        # Use Dask to read multiple CSVs in parallel\n",
    "        # Assuming header=None and relevant columns are known by index (e.g., 27 for TotlCycle)\n",
    "        raw = dd.read_csv(selected_files, blocksize=\"64MB\", header=None, encoding='utf-8',\n",
    "                          usecols=[27, 28, 29, 30, 31, 32]) # Example columns: TotlCycle, DchgCap, ChgCap, Eff, Temp, ...\n",
    "        \n",
    "        # Filter by cycle range early using Dask's query for efficiency\n",
    "        raw = raw[(raw[27] >= start_cycle) & (raw[27] <= end_cycle)]\n",
    "        \n",
    "        # Rename columns for clarity after filtering\n",
    "        raw = raw.rename(columns={27: 'TotlCycle', 28: 'DchgCap[mAh]', 29: 'ChgCap[mAh]',\n",
    "                                  30: 'Eff', 31: 'AvgTemp[C]', 32: 'Condition'}) # Example renaming\n",
    "        \n",
    "        # Optimize data types\n",
    "        raw = raw.astype({\n",
    "            'TotlCycle': 'int32',\n",
    "            'DchgCap[mAh]': 'float32',\n",
    "            'ChgCap[mAh]': 'float32',\n",
    "            'Eff': 'float32',\n",
    "            'AvgTemp[C]': 'float32',\n",
    "            'Condition': 'int8'\n",
    "        })\n",
    "\n",
    "        return raw.compute()\n",
    "    except Exception as e:\n",
    "        err_msg(f"Error reading PNE cycle files: {e}")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_pne_profile(path, ini_cycle):\n",
    "    restore_path = os.path.join(path, \"Restore\")\n",
    "    if not os.path.isdir(restore_path):\n",
    "        err_msg(f"PNE Restore directory not found: {restore_path}")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f"Loading PNE profile data from {restore_path}")\n",
    "    # Find all SaveData files\n",
    "    profile_files = [os.path.join(restore_path, f) for f in os.listdir(restore_path) if \"SaveData\" in f and f.endswith(\".csv\")]\n",
    "\n",
    "    if not profile_files:\n",
    "        err_msg(f"No PNE SaveData files found in {restore_path}")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        # Use Dask to read multiple profile CSVs. Include path column to identify source file if needed.\n",
    "        # Assuming header=None and relevant columns are known by index (e.g., 1 for Time, 2 for Voltage, 3 for Current, 27 for TotlCycle)\n",
    "        raw = dd.read_csv(profile_files, blocksize=\"64MB\", header=None, encoding='utf-8',\n",
    "                          usecols=[1, 2, 3, 27]) # Example columns: Time, Voltage, Current, TotlCycle\n",
    "        \n",
    "        # Filter by initial cycle if necessary (assuming 'col_27' is TotlCycle)\n",
    "        raw = raw[raw[27] >= ini_cycle] # Filter from ini_cycle onwards\n",
    "\n",
    "        # Rename columns for clarity\n",
    "        raw = raw.rename(columns={1: 'PassTime[Sec]', 2: 'Voltage[V]', 3: 'Current[mA]', 27: 'TotlCycle'})\n",
    "\n",
    "        # Optimize data types\n",
    "        raw = raw.astype({\n",
    "            'PassTime[Sec]': 'float32',\n",
    "            'Voltage[V]': 'float32',\n",
    "            'Current[mA]': 'float32',\n",
    "            'TotlCycle': 'int32'\n",
    "        })\n",
    "\n",
    "        processed = pne_data(raw, ini_cycle) # Apply PNE specific processing\n",
    "        return processed.compute()\n",
    "    except Exception as e:\n",
    "        err_msg(f"Error reading PNE profile files: {e}")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Step 5: Visualization (simplified placeholders)\n",
    "def graph_cycle(x, y, ax, title=\"Cycle Data\", xlabel=\"Cycle\", ylabel=\"Value\", color='blue'):\n",
    "    ax.plot(x, y, color=color)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "def graph_profile(x, y, ax, title=\"Profile Data\", xlabel=\"Time (min)\", ylabel=\"Voltage (V)\", color='red'):\n",
    "    ax.plot(x, y, color=color)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "def visualize(df_cycle, df_profile):\n",
    "    print(\"Generating visualizations...")\n",
    "    if not df_cycle.empty:\n",
    "        fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "        # Ensure 'TotlCycle' is available for x-axis and 'Dchg' for y-axis\n",
    "        if 'TotlCycle' in df_cycle.columns and 'Dchg' in df_cycle.columns:\n",
    "            graph_cycle(df_cycle['TotlCycle'], df_cycle['Dchg'], ax1, title=\"Discharge Capacity vs. Cycle\")\n",
    "        elif 'TotlCycle' in df_cycle.columns and 'DchgCap[mAh]' in df_cycle.columns:\n",
    "            graph_cycle(df_cycle['TotlCycle'], df_cycle['DchgCap[mAh]'], ax1, title=\"Discharge Capacity vs. Cycle\")\n",
    "        else:\n",
    "            print(\"Warning: 'TotlCycle' or 'Dchg'/'DchgCap[mAh]' not found in cycle data for visualization.\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No cycle data to visualize.\")\n",
    "\n",
    "    if not df_profile.empty:\n",
    "        fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "        # Ensure 'TimeMin' and 'Vol' are available for x and y axes\n",
    "        if 'TimeMin' in df_profile.columns and 'Vol' in df_profile.columns:\n",
    "            graph_profile(df_profile['TimeMin'], df_profile['Vol'], ax2, title=\"Voltage Profile\")\n",
    "        elif 'PassTime[Sec]' in df_profile.columns and 'Voltage[V]' in df_profile.columns:\n",
    "            graph_profile(df_profile['PassTime[Sec]']/60, df_profile['Voltage[V]'], ax2, title=\"Voltage Profile\")\n",
    "        else:\n",
    "            print(\"Warning: 'TimeMin' or 'Vol' not found in profile data for visualization.\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No profile data to visualize.\")\n",
    "\n",
    "# Step 6: Overall function wrapper\n",
    "def load_battery_data(path, start_cycle=1, end_cycle=10, min_cap=0, cutoff=0.05, ini_rate=0.2):\n",
    "    print(f"Starting data loading for path: {path}")\n",
    "    is_pne = check_cycler(path)\n",
    "    if is_pne is None:\n",
    "        return pd.DataFrame(), pd.DataFrame() # Return empty DataFrames on error\n",
    "\n",
    "    cycle_df = pd.DataFrame()\n",
    "    profile_df = pd.DataFrame()\n",
    "\n",
    "    if not is_pne:\n",
    "        print(\"Detected Toyo cycler data.\")\n",
    "        cycle_df = load_toyo_cycle(path, min_cap, ini_rate)\n",
    "        profile_df = load_toyo_profile(path, start_cycle, end_cycle, min_cap, cutoff, ini_rate)\n",
    "    else:\n",
    "        print(\"Detected PNE cycler data.\")\n",
    "        cycle_df = load_pne_cycle(path, start_cycle, end_cycle)\n",
    "        profile_df = load_pne_profile(path, start_cycle) # PNE profile typically loads all and filters later\n",
    "\n",
    "    merged_df = pd.DataFrame()\n",
    "    if not cycle_df.empty and not profile_df.empty:\n",
    "        print(\"Merging cycle and profile data...")\n",
    "        # Ensure 'TotlCycle' is present in both for merging\n",
    "        if 'TotlCycle' in cycle_df.columns and 'TotlCycle' in profile_df.columns:\n",
    "            merged_df = pd.merge(profile_df, cycle_df, on='TotlCycle', how='left', suffixes=('_profile', '_cycle'))\n",
    "            print(\"Data merged successfully.\")\n",
    "        else:\n",
    "            print(\"Warning: 'TotlCycle' not found in both cycle and profile data. Skipping merge.\")\n",
    "    elif cycle_df.empty and not profile_df.empty:\n",
    "        print(\"Only profile data loaded. Skipping merge.\")\n",
    "        merged_df = profile_df\n",
    "    elif not cycle_df.empty and profile_df.empty:\n",
    "        print(\"Only cycle data loaded. Skipping merge.\")\n",
    "        merged_df = cycle_df\n",
    "    else:\n",
    "        print(\"No data loaded.\")\n",
    "\n",
    "    visualize(cycle_df, profile_df)\n",
    "    \n",
    "    print(\"Data loading and processing complete.\")\n",
    "    return cycle_df, profile_df, merged_df\n",
    "\n",
    "# Example Usage (for testing within the notebook)\n",
    "# Replace with your actual data path\n",
    "# data_path = \"D:/battery_data_folder\" \n",
    "# For testing, let's use a path that might exist in the current structure or a dummy path\n",
    "# You would need to adjust this to a real path containing your battery data\n",
    "data_path = os.path.join(os.getcwd(), 'Rawdata', 'A1_MP1_4500mAh_T23_1') # Example path\n",
    "print(f"Attempting to load data from: {data_path}")\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    cycle_data, profile_data, merged_data = load_battery_data(data_path, start_cycle=1, end_cycle=5)\n",
    "    print("\nCycle Data Head:")\n",
    "    print(cycle_data.head())\n",
    "    print("\nProfile Data Head:")\n",
    "    print(profile_data.head())\n",
    "    print("\nMerged Data Head:")\n",
    "    print(merged_data.head())\n",
    "else:\n",
    "    print(f"The specified data path does not exist: {data_path}. Please update 'data_path' to a valid directory containing battery data.")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}